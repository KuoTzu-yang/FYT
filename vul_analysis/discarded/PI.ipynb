{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate CNN model, epoch: 1 ...\n",
      "acc: 0.877\n",
      "Generate CNN model, epoch: 2 ...\n",
      "acc: 0.942\n",
      "Generate CNN model, epoch: 3 ...\n",
      "acc: 0.963\n",
      "train acc: 0.963\n",
      "test acc: 0.89\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'MNIST_models.CNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.98\n",
      "test acc: 0.99\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import PI\n",
    "\n",
    "meta_params = {\n",
    "    'num_of_train_dataset': 1000,\n",
    "    'num_of_test_dataset': 100,\n",
    "    'is_flatten': False, \n",
    "    'adv_attack': 'i_FGSM',\n",
    "    'is_debug': False\n",
    "}\n",
    "\n",
    "PI = PI.PIInterface(meta_params)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from MNIST_models import *\n",
    "model = CNN()\n",
    "loss_func, optimizer = nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model = PI.train_model(model, loss_func, optimizer, 3)\n",
    "PI.set_model(model)\n",
    "print('train acc:', PI.eval_model('train'))\n",
    "print('test acc:', PI.eval_model('test'))\n",
    "print()\n",
    "\n",
    "model = load_model('store/MNIST_CNN.pt')\n",
    "PI.set_model(model)\n",
    "print('train acc:', PI.eval_model('train'))\n",
    "print('test acc:', PI.eval_model('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4e14547f2f43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_LPs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mB_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_TNR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_ASR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_TNR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_TPR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB_LPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_LPs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB_LPs_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_LPs_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_algorithm_on_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/CS research/FYT New/vul_analysis/PI.py\u001b[0m in \u001b[0;36mevaluate_algorithm_on_test_set\u001b[0;34m(self, verbose, on_retrained_model, on_twisted_model)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         self._set_differentation_lines(\n\u001b[0;32m--> 148\u001b[0;31m             95, on_retrained_model, on_twisted_model)\n\u001b[0m\u001b[1;32m    149\u001b[0m         B_num_count, B_correct_count, B_valid_count, B_LPs, B_LPs_score = self._evaluate_benign_samples(\n\u001b[1;32m    150\u001b[0m             verbose, on_retrained_model, on_twisted_model)\n",
      "\u001b[0;32m~/Desktop/CS research/FYT New/vul_analysis/PI.py\u001b[0m in \u001b[0;36m_set_differentation_lines\u001b[0;34m(self, qr, on_retrained_model, on_twisted_model)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;31m# Collect LP_risk_score among train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             _, _, LP_risk_score = self.property_match(\n\u001b[0;32m--> 188\u001b[0;31m                 x, y_, on_retrained_model, on_twisted_model, verbose=False)\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mLPs_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLP_risk_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS research/FYT New/vul_analysis/PI.py\u001b[0m in \u001b[0;36mproperty_match\u001b[0;34m(self, x, y, on_retrained_model, on_twisted_model, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_all_LP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_type'"
     ]
    }
   ],
   "source": [
    "PI.generate_LPs()\n",
    "(B_accuracy, B_TNR), (A_accuracy, A_ASR, A_TNR, A_TPR), (B_LPs, A_LPs), (B_LPs_score, A_LPs_score) = PI.evaluate_algorithm_on_test_set(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dropout_rates = [0.05*i for i in range(0, 21)]\n",
    "# dropout_rates = [0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.9]\n",
    "savefig = True \n",
    "num_of_rob_train_eps = 10\n",
    "first_fig_prefix_str = 'exp_15_1_'\n",
    "second_fig_prefix_str = 'exp_15_2_'\n",
    "ASRs = []\n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "    print('dropout_rate:', dropout_rate)\n",
    "    PI.set_dropout_rate(dropout_rate)\n",
    "    PI.generate_twisted_model('CNN', num_of_rob_train_eps)\n",
    "    PI.generate_LPs(on_twisted_model=True)    \n",
    "    \n",
    "    # Computation \n",
    "    (B_accuracy, B_TNR), (A_accuracy, A_ASR, A_TNR, A_TPR), (B_LPs, A_LPs), (B_LPs_score, A_LPs_score) = PI.evaluate_algorithm_on_test_set(True, on_retrained_model=False, on_twisted_model=True)\n",
    "    ASRs.append(A_ASR)\n",
    "    print('Attack success rates:', ASRs)\n",
    "    \n",
    "    BLPs, ALPs = np.array(B_LPs), np.array(A_LPs) \n",
    "    BLPs[BLPs=='benign'] = 1\n",
    "    BLPs[BLPs=='adversarial'] = 0\n",
    "    BLPs = BLPs.astype(np.int)\n",
    "    prob_BLPs = np.sum(BLPs, axis=0) / BLPs.shape[0]\n",
    "    ALPs[ALPs=='benign'] = 1\n",
    "    ALPs[ALPs=='adversarial'] = 0\n",
    "    ALPs = ALPs.astype(np.int)\n",
    "    prob_ALPs = np.sum(ALPs, axis=0) / ALPs.shape[0]\n",
    "    results = (prob_ALPs, prob_BLPs, A_LPs_score, B_LPs_score)\n",
    "    \n",
    "    # Visualize experimental results \n",
    "    draw_exp_results(results, dropout_rate, savefig=savefig, first_fig_prefix_str=first_fig_prefix_str, second_fig_prefix_str=second_fig_prefix_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ASRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.arange(len(ASRs))\n",
    "plt.plot(dropout_rates[:len(ASRs)], ASRs, color='g')\n",
    "plt.ylim((0,1))\n",
    "plt.savefig('ASR_vs_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
