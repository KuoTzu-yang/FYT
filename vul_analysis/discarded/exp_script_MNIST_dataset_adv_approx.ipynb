{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='./data', transform=transforms.ToTensor(), train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', transform=transforms.ToTensor(), train=False, download=True)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1000, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=2000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 784) (600,)\n",
      "(600, 784) (600,)\n",
      "(1000, 784) (1000,)\n"
     ]
    }
   ],
   "source": [
    "def create_robust_dataset(size_of_dataset):\n",
    "    import random\n",
    "    random_batch_idx = (random.randint(0, len(loader)-1))\n",
    "    samples, labels = None, None \n",
    "    for idx, (samples, labels) in enumerate(loader):\n",
    "        if idx == random_batch_idx:\n",
    "            samples = samples.reshape(-1, 784).numpy()\n",
    "            labels = labels.numpy()\n",
    "            samples = samples[:size_of_dataset]\n",
    "            labels = labels[:size_of_dataset]\n",
    "            break\n",
    "    \n",
    "    return samples, labels\n",
    "\n",
    "def create_non_robust_dataset(size_of_dataset):\n",
    "    import random\n",
    "    random_batch_idx = (random.randint(0, len(loader)-1))\n",
    "    samples, labels = None, None \n",
    "    for idx, (samples, labels) in enumerate(loader):\n",
    "        if idx == random_batch_idx:\n",
    "            samples = samples.reshape(-1, 784).numpy()\n",
    "            labels = labels.numpy()\n",
    "            samples = samples[:size_of_dataset]\n",
    "            labels = labels[:size_of_dataset]\n",
    "            break\n",
    "    \n",
    "    return samples, labels\n",
    "\n",
    "def create_test_dataset(size_of_dataset):\n",
    "    samples, labels = None, None \n",
    "    for idx, (samples, labels) in enumerate(test_loader):\n",
    "        if idx == 0:\n",
    "            samples = samples.reshape(-1, 784).numpy()\n",
    "            labels = labels.numpy()\n",
    "            samples = samples[:size_of_dataset]\n",
    "            labels = labels[:size_of_dataset]\n",
    "            break\n",
    "    \n",
    "    return samples, labels\n",
    "\n",
    "    \n",
    "size_of_dataset = 600\n",
    "robust_X, robust_Y = create_robust_dataset(size_of_dataset)\n",
    "print(robust_X.shape, robust_Y.shape)\n",
    "non_robust_X, non_robust_Y = create_non_robust_dataset(size_of_dataset)\n",
    "print(non_robust_X.shape, non_robust_Y.shape)\n",
    "\n",
    "test_X, test_Y = create_test_dataset(1000)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robustness indication (robust dataset): -91.50874376296997\n",
      "Robustness indication (non robust dataset): -89.11045217514038\n"
     ]
    }
   ],
   "source": [
    "from math import inf\n",
    "from numpy.linalg import norm\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "def return_close_i(i, X_cluster_mean):\n",
    "    min_j, min_distance = None, inf\n",
    "    for j in range(len(X_cluster_mean)):\n",
    "        if i != j:\n",
    "            distance = norm(X_cluster_mean[j] - X_cluster_mean[i])\n",
    "            if distance < min_distance:\n",
    "                min_distance, min_j = distance, j\n",
    "    return min_j, min_distance\n",
    "\n",
    "def compute_robustness_indication(X, Y):\n",
    "    X_cluster = []\n",
    "    for class_idx in range(num_classes):\n",
    "        cluster_array = [x for (idx, x) in enumerate(X) if Y[idx] == class_idx]\n",
    "#         print('Length of cluster array:', len(cluster_array))\n",
    "        try: \n",
    "            cluster = np.array(cluster_array)\n",
    "        except: \n",
    "            print(cluster_array)\n",
    "            cluster = np.array(cluster_array)\n",
    "            print(cluster)\n",
    "        X_cluster.append(cluster)\n",
    "        \n",
    "    \n",
    "    X_cluster_mean = [np.mean(X, axis=0) for X in X_cluster]\n",
    "    X_cluster_std = [np.std(X, axis=0) for X in X_cluster]\n",
    "\n",
    "    r = 0\n",
    "    for i in range(num_classes):\n",
    "        close_i, close_i_distance = return_close_i(i, X_cluster_mean)\n",
    "        r += close_i_distance - norm(X_cluster_std[i]) - norm(X_cluster_std[close_i])\n",
    "    return r\n",
    "\n",
    "robust_r = compute_robustness_indication(robust_X, robust_Y)\n",
    "non_robust_r = compute_robustness_indication(non_robust_X, non_robust_Y)\n",
    "\n",
    "print('Robustness indication (robust dataset):', robust_r)\n",
    "print('Robustness indication (non robust dataset):', non_robust_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/torch/tensor.py:293: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 20\n",
      "3 / 20\n",
      "4 / 20\n",
      "5 / 20\n",
      "6 / 20\n",
      "7 / 20\n",
      "8 / 20\n",
      "9 / 20\n",
      "10 / 20\n",
      "11 / 20\n",
      "12 / 20\n",
      "13 / 20\n",
      "14 / 20\n",
      "15 / 20\n",
      "16 / 20\n",
      "17 / 20\n",
      "18 / 20\n",
      "19 / 20\n",
      "20 / 20\n",
      "1 / 20\n",
      "2 / 20\n",
      "3 / 20\n",
      "4 / 20\n",
      "5 / 20\n",
      "6 / 20\n",
      "7 / 20\n",
      "8 / 20\n",
      "9 / 20\n",
      "10 / 20\n",
      "11 / 20\n",
      "12 / 20\n",
      "13 / 20\n",
      "14 / 20\n",
      "15 / 20\n",
      "16 / 20\n",
      "17 / 20\n",
      "18 / 20\n",
      "19 / 20\n",
      "20 / 20\n"
     ]
    }
   ],
   "source": [
    "# Create two models corresponding to robust and non-robust dataset \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class NaiveC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 64)\n",
    "        self.layer2 = nn.Linear(64, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.relu(self.layer1(x))\n",
    "        return self.layer2(output)\n",
    "\n",
    "class NormalC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 64)\n",
    "        self.layer2 = nn.Linear(64, 16)\n",
    "        self.layer3 = nn.Linear(16, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.layer1(x))\n",
    "        h2 = self.relu(self.layer2(h1))\n",
    "        return self.layer3(h2)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "def generate_Cs(X, Y, verbose=False):\n",
    "    first_model = NaiveC()\n",
    "    second_model = NormalC()\n",
    "    \n",
    "    # Create ResNet\n",
    "    \n",
    "    third_model = Net()\n",
    "    third_optimizer = optim.SGD(third_model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    # Optimizer parameters\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    lr = 1e-3\n",
    "    first_optimizer = torch.optim.Adam(first_model.parameters(), lr=lr)\n",
    "    second_optimizer = torch.optim.Adam(second_model.parameters(), lr=lr)\n",
    "    loss_history = []\n",
    "\n",
    "    # Training\n",
    "    num_of_epochs = 20\n",
    "    for epoch in range(num_of_epochs):\n",
    "        print(epoch+1, '/', num_of_epochs)\n",
    "        for idx, data in enumerate(X):\n",
    "            data = torch.from_numpy(np.expand_dims(data, axis=0).astype(np.float32))\n",
    "            label = torch.from_numpy(np.array([Y[idx]]).astype(np.int64))\n",
    "    \n",
    "            # Forwarding (First model)\n",
    "            prediction = first_model.forward(data)\n",
    "            loss = loss_func(prediction, label)\n",
    "            if verbose:\n",
    "                print('Epoch:', epoch, 'Loss:', loss)\n",
    "\n",
    "            # Optimization (back-propogation)\n",
    "            first_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            first_optimizer.step()\n",
    "            loss_history.append(loss.item())\n",
    "            \n",
    "            # Forwarding (Second model)\n",
    "            prediction = second_model.forward(data)\n",
    "            loss = loss_func(prediction, label)\n",
    "            if verbose:\n",
    "                print('Epoch:', epoch, 'Loss:', loss)\n",
    "\n",
    "            # Optimization (back-propogation)\n",
    "            second_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            second_optimizer.step()\n",
    "            loss_history.append(loss.item())\n",
    "            \n",
    "            # Forwarding (Third model)\n",
    "            train  = data.resize(1, 1, 28, 28)\n",
    "            third_optimizer.zero_grad()\n",
    "            output = third_model(train)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            third_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            third_optimizer.step()\n",
    "            \n",
    "    models = [first_model, second_model, third_model]\n",
    "    return loss_history, models\n",
    "            \n",
    "robust_loss_history, robust_models = generate_Cs(robust_X, robust_Y, verbose=False)\n",
    "non_robust_loss_history, non_robust_models = generate_Cs(non_robust_X, non_robust_Y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust model accurancy: 1.0\n",
      "Robust model accurancy: 1.0\n",
      "torch.Size([600, 1, 28, 28])\n",
      "Robust model accurancy: 0.605\n",
      "Non robust model accurancy: 1.0\n",
      "Non robust model accurancy: 1.0\n",
      "torch.Size([600, 1, 28, 28])\n",
      "Non robust model accurancy: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "def eval_model(X, Y, model):\n",
    "    datas = torch.from_numpy(X.astype(np.float32))\n",
    "    labels = torch.from_numpy(Y.astype(np.int64))\n",
    "    \n",
    "    # Forwarding\n",
    "    try:\n",
    "        outputs = model.forward(datas).detach().numpy()\n",
    "    except:\n",
    "        train  = datas.resize(X.shape[0], 1, 28, 28)\n",
    "        outputs = model.forward(train).detach().numpy()\n",
    "        \n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "\n",
    "    total = labels.shape[0]\n",
    "    correct = (predictions == labels.numpy()).sum().item()\n",
    "    acc = correct/total\n",
    "    \n",
    "    return acc\n",
    "\n",
    "for robust_model in robust_models:\n",
    "    robust_acc = eval_model(robust_X, robust_Y, robust_model)\n",
    "    print('Robust model accurancy:', robust_acc)\n",
    "\n",
    "for non_robust_model in non_robust_models:\n",
    "    non_robust_acc = eval_model(non_robust_X, non_robust_Y, non_robust_model)\n",
    "    print('Non robust model accurancy:', non_robust_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5xcdX3/8dd7Z3c22SVXsiBLAuEuiSDqCiIqaAURFfShLSAVtFiqgrbVnxZ+VkDUltZa7c+qiEIRLSBqlRRpAbkqcknAgEm4hXBJCCQbQhJy38vn98c5szmZ7GWy2d3ZPfN+Ph7zmJnz/Z5zPnNm9zPf+Z7vnK8iAjMzy6+6agdgZmbDy4nezCznnOjNzHLOid7MLOec6M3Mcs6J3sws55zoDUkzJYWk+grqflTS74Y5noWSjhuG7R4nadlQb3copMf/wFEQx8WSflLtOGxoOdGPMZKekbRV0rSy5fPTZDGzOpHt3AdGfyJidkTcOURh1azh/lCWdJWkrw7X9kd6P3nmRD82PQ2cXnoi6TBgfPXCqdyufgiMRbX4mm10caIfm34MnJl5fhZwdbaCpEmSrpbULulZSX8vqS4tK0j6F0mrJC0B3tPLuldIekHS85K+KqlQQVx3p/drJK2XdHTaqrxH0jclrQYulnSApNslvZTG8J+SJmf2/4ykd6aPL5Z0ffpaXkm7ddoydVsl/SJ9nU9L+kymbHzaGnxZ0iLgjf0FL+nNkuZKWpvevzlTdqekr6Sv5RVJt5R/q8rUPU7SMkl/J+lF4D/S5X8pabGk1ZLmSGotW/UkSUvSY/L1zPu1XXdK+Ten9BgvSeN6WtIZkg4FLgOOTt+LNX3Eup+ku9J1bwXKvyn+TNKL6TG5W9LsdPk5wBnAF9Lt/3e6/HxJT6XbWyTpA5ltHZjua236Gn+aKXu1pFvTY/O4pD/rbz+2kyLCtzF0A54B3gk8DhwKFIClwL5AADPTelcDNwATgJnAE8DZadkngMeAGcBU4I503fq0/FfA94FmYA/gAeCv0rKPAr/rI7aZ2e1k6ncCnwbqSb55HAgcDzQCLSQfEN8qf43p44uBzcBJ6Wv9R+C+tKwOeBC4ECgC+wNLgHel5ZcCv01f4wxgAbCsj9inAi8DH0njPD19vntafifwFHBw+hruBC7tY1vHpa/5n9LXOB54B7AKeH267NvA3Zl1In0fpgL7pO/XxzPH4Ce9Hef0PVoHHJKW7QXMHui9ymzrXuBf05jeBrxStq+/IPkbagS+BczPlF0FfLVse38KtKbvzanABmCvtOxa4Itp2TjgLenyZpK/4Y+lr+n16bGa3dd+fNvJvFHtAHzbyTdsW6L/+zTpnQjcmv6DRJoECsAWYFZmvb8C7kwf3w58IlN2QiZx7JmuOz5TfjpwR/q4z+RB34n+uQFe0/uBP5S/xvTxxcBvMmWzgE3p46PKtw1cAPxH+ngJcGKm7Bz6TvQfAR4oW3Yv8NH08Z3A32fKPgX8bx/bOg7YCozLLLsC+OfM892ADrZ9MEdZrJ8Cbsscg/4S/Rrgg9n3bKD3Ki3fh+QDqTmz7JrsvsrqT073Oyl9fhUDJGBgPnBK+vhq4HJgelmdU4Hfli37PnBRpfvxrf+bu27Grh8DHyb5Z766rGwaSQv32cyyZ4G908etJC2obFnJvkAD8IKkNelX/u+TtOwHK7svJO0h6bq0W2gd8BPKugzKvJh5vBEYl3Zb7Au0luJMY/2/JB9W0P/rLNfaS3n2mPUWx279bK89Ijb3tf2IWA+8VLb98ljLu3Z2EBEbSBLlJ0jes19LevVA62ViejndRna/QE8X36VpV8w6kg9g6Oe9knSmkoEBpffjNZn6XwAEPJB2wf1Funxf4Kiy9/EM4FUVvg4bgBP9GBURz5KclD0J+K+y4lUkrcV9M8v2AZ5PH79A0pWRLStZStKinxYRk9PbxIiYXUlYFS7/x3TZ4RExEfhzkgSws5YCT2finBwREyLipLS8v9dZbjnbH69S/ed7qVuJ8te83fYlNQO7l22/PNbl6eMNQFOmbLsEGBE3R8TxJN02jwE/6COGci8AU9JYsvst+TBwCsk3yEkk3yRg23u13fYl7Zvu+zySLq/JJN1lSuN8MSL+MiJaSb5hflfJkNKlwF1l7+NuEfHJCl+HDcCJfmw7G3hHWYuMiOgCrge+JmlC+g/4WZKWM2nZZyRNlzQFOD+z7gvALcA3JE2UVJeePD22gnjagW6SvvL+TADWk5y03Rv4fAXb7s0DwLr0pOf4tAX6Gkmlk67XAxdImiJpOsl5gr7cBBws6cOS6iWdStJNdOMgYyt3DfAxSUdIagT+Abg/Ip7J1Pl8GusM4K+B0snK+cDbJO0jaRJJ9xQAkvaUdHKarLeQHNeutHgFMF1SsbeA0sbCPODLkoqS3gK8L1NlQrrNl0g+aP6hbBMr2P69biZJyu1pbB8jadGXYv3T9H2A5PxHpLHeSHLsPyKpIb29MT2h3Nt+bCc50Y9hEfFURMzro/jTJC3BJcDvSBLNlWnZD4CbgYeBh9jxG8GZJF0/i0j+IX9O0locKJ6NwNeAe9Kv4G/qo+qXSU64rQV+3cv+K5J+oL0POILk280q4Ickrc/SfkrffG4h6e7qa1svAe8FPkeS2L4AvDciVg0mtl62fxvwJeAXJC3pA4DTyqrdQHJyeT7JcbkiXfdWkqT/SFqe/fCpS2NeDqwGjiXp34fkXMxC4EVJfb2OD5Oc61gNXMT23YBXkxy/50n+Fu4rW/cKYFb6Xv8qIhYB3yA5t7ECOAy4J1P/jcD9ktYDc4C/joinI+IVkvNEp6Wv40W2ncjeYT99vA7rh9KTHWZmllNu0ZuZ5ZwTvZlZzjnRm5nlnBO9mVnOjcqLLU2bNi1mzpxZ7TDMzMaMBx98cFVEtPRWNioT/cyZM5k3r69Rg2ZmVk5Sn7/8dteNmVnOOdGbmeWcE72ZWc450ZuZ5ZwTvZlZzjnRm5nlnBO9mVnODZjoJV0paaWkBX2Ufz6dUWa+pAWSuiRNTcuekfTHtGzYB8Z/+7YnueuJ9uHejZnZmFJJi/4qknlJexURX4+IIyLiCJIJEe6KiNWZKm9Py9t2LdSBXXbXU9ztRG9mtp0BE31E3E0yKUElTieZ6b0qmhrr2bi1s1q7NzMblYasj15SE0nL/xeZxQHcIulBSecMsP45kuZJmtfePrhWeXOxwIYtXQNXNDOrIUN5MvZ9wD1l3TbHRMTrgXcD50p6W18rR8TlEdEWEW0tLb1el2dATUW36M3Myg1loj+Nsm6biFie3q8EfgkcOYT720Fzo1v0ZmblhiTRpzPTH0syuXFpWbOkCaXHJJP/9jpyZ6i4RW9mtqMBL1Ms6VrgOGCapGUkM8U3AETEZWm1DwC3RMSGzKp7Ar+UVNrPNRHxv0MX+o6aGws8v8YtejOzrAETfUScXkGdq0iGYWaXLQFeO9jABqOpWM/GLW7Rm5ll5eqXsc3FAhu2ukVvZpaVq0TvcfRmZjvKVaJvLhbo6Aq2dnZXOxQzs1EjV4m+qZiccnCr3sxsm1wl+ubGAoD76c3MMnKV6Hta9B55Y2bWI1eJvtSi3+gWvZlZj1wl+lKLfoP76M3MeuQq0Tf3dN24RW9mVpKrRN/UczLWLXozs5JcJfqeFr376M3MeuQq0Y8vpi16j7oxM+uRq0TfVPSoGzOzcrlK9A2FOor1de6jNzPLyFWih+R6Nx51Y2a2Te4SfVOx3i16M7OM3CX65ka36M3MsnKX6N2iNzPbXu4SfXNjwaNuzMwyBkz0kq6UtFLSgj7Kj5O0VtL89HZhpuxESY9LWizp/KEMvC9NxXqPozczy6ikRX8VcOIAdX4bEUekt0sAJBWA7wDvBmYBp0uatSvBVqK56Ba9mVnWgIk+Iu4GVg9i20cCiyNiSURsBa4DThnEdnaK5401M9veUPXRHy3pYUn/I2l2umxvYGmmzrJ0Wa8knSNpnqR57e3tgw6kuVhgg0fdmJn1GIpE/xCwb0S8Fvg28Kt0uXqpG31tJCIuj4i2iGhraWkZdDBNxXo2dXTR1d3nrszMasouJ/qIWBcR69PHNwENkqaRtOBnZKpOB5bv6v4GUpplalOHW/VmZjAEiV7SqyQpfXxkus2XgLnAQZL2k1QETgPm7Or+BuJ5Y83Mtlc/UAVJ1wLHAdMkLQMuAhoAIuIy4EPAJyV1ApuA0yIigE5J5wE3AwXgyohYOCyvIqO5Z/IRt+jNzKCCRB8Rpw9Q/u/Av/dRdhNw0+BCG5yeeWPdojczA/L4y1jPMmVmtp3cJXrPG2tmtr3cJfqeFr3H0puZATlM9KXpBN2iNzNL5C7RNzd6eKWZWVbuEv22Fr27bszMIIeJvrG+jkKdfGEzM7NU7hK9JJp8YTMzsx65S/SQjLzZ5K4bMzMgp4m+qbHgUTdmZqlcJvrmYr1/GWtmlsplok/66N2iNzODnCb65ka36M3MSnKZ6JuK7qM3MyvJZaJvLtb7WjdmZqlcJvrxbtGbmfXIZaJvbiywcWsXyURXZma1LZeJvqlYT1d3sKWzu9qhmJlVXS4TfXN6YTOPvDEzqyDRS7pS0kpJC/ooP0PSI+nt95Jemyl7RtIfJc2XNG8oA+9PU6PnjTUzK6mkRX8VcGI/5U8Dx0bE4cBXgMvLyt8eEUdERNvgQtx5njfWzGyb+oEqRMTdkmb2U/77zNP7gOm7Htau8byxZmbbDHUf/dnA/2SeB3CLpAclndPfipLOkTRP0rz29vZdCsLzxpqZbTNgi75Skt5Okujfkll8TEQsl7QHcKukxyLi7t7Wj4jLSbt92tradmlcpOeNNTPbZkha9JIOB34InBIRL5WWR8Ty9H4l8EvgyKHY30B65o11ojcz2/VEL2kf4L+Aj0TEE5nlzZImlB4DJwC9jtwZaqXhlZ5lysysgq4bSdcCxwHTJC0DLgIaACLiMuBCYHfgu5IAOtMRNnsCv0yX1QPXRMT/DsNr2EGTW/RmZj0qGXVz+gDlHwc+3svyJcBrd1xj+I1vcIvezKwkl7+MLdSJ8Q0Ft+jNzMhpoofkwmYb/IMpM7P8JvqmYj0bfQkEM7M8J3q36M3MIMeJPpk31i16M7PcJvqmYsGjbszMyHGiby66RW9mBjlO9E2NbtGbmUGOE71b9GZmidwm+iaPozczA3Kc6JuL9Wzt7KazyxOEm1lty22iL12TfmOHW/VmVttym+h7rknvE7JmVuNym+g9y5SZWSK3id7zxpqZJXKb6Jsa3aI3M4McJ/qeFr0TvZnVuPwm+kbPMmVmBjlO9E1u0ZuZARUmeklXSlopaUEf5ZL0/yQtlvSIpNdnys6S9GR6O2uoAh9IqevGLXozq3WVtuivAk7sp/zdwEHp7RzgewCSpgIXAUcBRwIXSZoy2GB3xvjSD6bcojezGldRoo+Iu4HV/VQ5Bbg6EvcBkyXtBbwLuDUiVkfEy8Ct9P+BMWSK9XU0FOTr3ZhZzRuqPvq9gaWZ58vSZX0t34GkcyTNkzSvvb19SILyvLFmZkOX6NXLsuhn+Y4LIy6PiLaIaGtpaRmSoJo9b6yZ2ZAl+mXAjMzz6cDyfpaPiCbPG2tmNmSJfg5wZjr65k3A2oh4AbgZOEHSlPQk7AnpshHR7Hljzcyor6SSpGuB44BpkpaRjKRpAIiIy4CbgJOAxcBG4GNp2WpJXwHmppu6JCL6O6k7pJo8y5SZWWWJPiJOH6A8gHP7KLsSuHLnQ9t1zY0Flq/pqMauzcxGjdz+Mhbcojczg5wn+mbPG2tmlu9E73H0ZmY5T/TNxQIbO7ro7u516L6ZWU3IdaJvaqwnAjZ3uvvGzGpXrhN9c9HXpDczy3Wi9zXpzcxynug9y5SZWc4TvVv0ZmY5T/Q9LXqPpTezGpbrRN/TovdYejOrYblO9D3zxrpFb2Y1LNeJvqnR88aameU60Tf3nIx1i97MaleuE/24hjok99GbWW3LdaKXRHOx3n30ZlbTcp3oAZqKBffRm1lNy32ib26s9y9jzaym5T7Ru0VvZrWuokQv6URJj0taLOn8Xsq/KWl+entC0ppMWVembM5QBl+J5qJb9GZW2wacHFxSAfgOcDywDJgraU5ELCrViYi/zdT/NPC6zCY2RcQRQxfyzmlqLPDyhq3V2r2ZWdVV0qI/ElgcEUsiYitwHXBKP/VPB64diuCGgkfdmFmtqyTR7w0szTxfli7bgaR9gf2A2zOLx0maJ+k+Se/vayeSzknrzWtvb68grMo0FQseR29mNa2SRK9elvU1CetpwM8jItuE3ici2oAPA9+SdEBvK0bE5RHRFhFtLS0tFYRVmeZGt+jNrLZVkuiXATMyz6cDy/uoexpl3TYRsTy9XwLcyfb998NuvEfdmFmNqyTRzwUOkrSfpCJJMt9h9IykQ4ApwL2ZZVMkNaaPpwHHAIvK1x1OzcUCHV3B1s7ukdytmdmoMeCom4jolHQecDNQAK6MiIWSLgHmRUQp6Z8OXBcR2W6dQ4HvS+om+VC5NDtaZyRkZ5kq1hdHctdmZqPCgIkeICJuAm4qW3Zh2fOLe1nv98BhuxDfLsvOMjW5qZqRmJlVRw38MtazTJlZbct9ove8sWZW63Kf6N2iN7Nal/tE73ljzazW5T7Re95YM6t1uU/0PS16X8HSzGpU7hO9W/RmVuvyn+gb0lE3btGbWY3KfaKvL9TRWF/nFr2Z1azcJ3ooXcHSid7MalNNJPrkmvTuujGz2lQTiT6ZZcotejOrTTWR6JsaC2z0D6bMrEbVRKJvLtazwZdAMLMaVROJvqnoFr2Z1a6aSPTNjfVO9GZWs2oi0Td53lgzq2E1keibG+v9y1gzq1k1keibigU2dXTR1R0DVzYzy5mKEr2kEyU9LmmxpPN7Kf+opHZJ89PbxzNlZ0l6Mr2dNZTBV6p0BctNHW7Vm1ntGXBycEkF4DvA8cAyYK6kORGxqKzqTyPivLJ1pwIXAW1AAA+m6748JNFXqOcKlls62a2xovnQzcxyo5IW/ZHA4ohYEhFbgeuAUyrc/ruAWyNidZrcbwVOHFyog+dZpsysllWS6PcGlmaeL0uXlfugpEck/VzSjJ1cF0nnSJonaV57e3sFYVWuqVi6VLFH3phZ7akk0auXZeVnNf8bmBkRhwO/AX60E+smCyMuj4i2iGhraWmpIKzKNafdNR5Lb2a1qJJEvwyYkXk+HVierRARL0XElvTpD4A3VLruSOhp0XssvZnVoEoS/VzgIEn7SSoCpwFzshUk7ZV5ejLwaPr4ZuAESVMkTQFOSJeNqJ4WvcfSm1kNGnAISkR0SjqPJEEXgCsjYqGkS4B5ETEH+Iykk4FOYDXw0XTd1ZK+QvJhAXBJRKwehtfRL7fozayWVTTWMCJuAm4qW3Zh5vEFwAV9rHslcOUuxLjLSqNuNg5wMnZzRxfj0jlmzczyoiZ+GTu+p0Xfd9fNTX98gcO/fAsvrN00UmGZmY2Imkj0jfV1FOrU74XNLr97CVs7u3no2TUjGJmZ2fCriUQviaZioc8Lmz2ybA3zlyYJfuHytSMZmpnZsKuZ6wE0F+v7bNFffe+zNBUL7DGhkYXL141wZGZmw6tmEn1TY6HXPvrVG7Yy5+Hl/FnbdDZ3dHPn40P7q1wzs2qria4bSFv0vYy6+encpWzt7ObMo2cyu3Uiq9ZvYeW6zVWI0MxseNROi764Y4u+qzv4yX3P8qb9p3LwnhNYs7EDgIXL17HHxHHVCNPMbMjVTou+ccc++tsfW8nzazZx1tEzATh0rwmAT8iaWb7UTKJvKhZ2uATC1fc+w16TxnH8rD0BmDCugX13b/IJWTPLlZpJ9M3F+u0ugfBU+3p+++QqzjhqH+oL2w7D7NaJTvRmlis1k+ibGrdv0f/43mdpKIhT37jPdvVmt07iudUbWbe5Y6RDNDMbFjWT6Est+ohg/ZZOfvHgMt5z2F60TGjcrt6s1okALHKr3sxyomYSfVNjge6ALZ3d/PIPz/PKlk7OfPPMHerNThO9u2/MLC9qJtGXrmC5fksnP773GV6z90ReN2PyDvX2mDCOlgmNHnljZrlRM4m+dE362x9byRMr1nPm0TORepvpMGnVu+vGzPKiZhJ9aZap79/1FJObGjj5ta191p3dOpEnV65nc4dnpDKzsa9mEn2pRf9U+wZOfeOMficYmd06ia7u4IkVr4xUeGZmw6ZmEn2pRS/Bnx+1b791fULWzPKkZhJ9qUX/J6/egxlTm/qtO2NKExMa631C1sxyoaJEL+lESY9LWizp/F7KPytpkaRHJN0mad9MWZek+eltzlAGvzNmTG1idutEPvX2AwesW1cnDvUvZM0sJwa8eqWkAvAd4HhgGTBX0pyIWJSp9gegLSI2Svok8M/AqWnZpog4Yojj3mkTxzXw68+8teL6s1snct0DS+nqDgp1vY/OMTMbCypp0R8JLI6IJRGxFbgOOCVbISLuiIiN6dP7gOlDG+bIm906iU0dXTy9an21QzEz2yWVJPq9gaWZ58vSZX05G/ifzPNxkuZJuk/S+/taSdI5ab157e3Vn+XJJ2TNLC8qSfS99VtErxWlPwfagK9nFu8TEW3Ah4FvSTqgt3Uj4vKIaIuItpaWlgrCGl4H7rEbxfo6J3ozG/MqSfTLgBmZ59OB5eWVJL0T+CJwckRsKS2PiOXp/RLgTuB1uxDviGko1HHInhM88sbMxrxKEv1c4CBJ+0kqAqcB242ekfQ64PskSX5lZvkUSY3p42nAMUD2JO6oVro2fUSvX2DMzMaEARN9RHQC5wE3A48C10fEQkmXSDo5rfZ1YDfgZ2XDKA8F5kl6GLgDuLRstM6oNrt1Ims2drB8rScLN7Oxq6LJwSPiJuCmsmUXZh6/s4/1fg8ctisBVtOs1kkALHx+LXtPHl/laMzMBqdmfhk7GIfuNQHJI2/MbGxzou9HU7Ge/ac1O9Gb2ZjmRD+A2a2TWOSRN2Y2hjnRD2B260SWr93Myxu2VjsUM7NBcaIfwOzSCVl335jZGOVEP4Btl0Jw942ZjU1O9AOY0lykddI4t+jNbMxyoq/ArNZJ/bboV63fwrnXPMTFcxaOYFRmZpWp6AdTtW5260Rue2wFG7d20lTc/pDd8dhKPv/zh1m1PjlZe9whLRx3yB7VCNPMrFdu0VdgdutEIuDRF7ZNFr65o4uLbljAx66ay7TdGrnx029h/5ZmLrxhIZs7uqoYrZnZ9pzoKzB772TkTWk8/aLl63jft3/Hj+59lrPfsh+/OvcYXrP3JL56ymt4bvVGvnvH4mqGa2a2HSf6CrROGsfkpgYWPL+OH/52Ce//zj2s2dTB1X9xJF967yzGNSQTj7/5wGm8/4hWLrtrCUvaPTOVmY0OTvQVkMTs1olc/+BSvvrrRzn2kBZu/pu38baDd5wg5YvvmUVjQx1fumGBL29sZqOCE32F3nzANBrr6/iHDxzG5R95A1Obi73Wa5nQyBfedQj3LH6JOQ/vMD+LmdmI02hsdba1tcW8efOqHcZ2urqDjq7unm6agep+4Lv38MLazdz2uWOZOK5hBCI0s1om6cF02tYduEVfoUKdKkrypbpfe/9hvLR+C9+4+fEB69/1RDtn/PA+bpj//K6GaWa2A4+jHyaHTZ/EmUfP5Ef3PsMH3zCdw6dP3qHO0tUb+cqNi7hl0QrGNdRxz+KXuP/p1VyYOcFrZrar3KIfRp894WCm7dbIF3+5gK7ubV1kmzu6+LffPMk7//UufvvkKj7/rkN46EvH81fH7s819z/HB777e55etaGifSxfs4kLb1jAR664n9seXeETwGa2A/fRD7M5Dy/nM9f+gUtOmc2ZR8/kN4tWcMmNi3hu9Ubec/hefPGkQ2nNTFN4+2Mr+Oz1D9PR2c2lHzyc9722tdftLl+zie/d+RQ/nbuU7gim7dbIi+s2c8SMyXz2+IN560HTkDRSL9PMqqy/PvqKEr2kE4F/AwrADyPi0rLyRuBq4A3AS8CpEfFMWnYBcDbQBXwmIm4eaH95SvQRwUeueICHl66hbeYU7ni8nQP32I0vnzybYw6c1us6y9ds4rxrHuKh59ZwxlH7bDdWvzzB/2nbDM59+wHsOXEcP39wGd++7UmWr93MkTOn8rfHH8zRB+w+ki/XzKpklxK9pALwBHA8sAyYC5weEYsydT4FHB4Rn5B0GvCBiDhV0izgWuBIoBX4DXBwRPR7jYA8JXqAp1dt4F3fvJuGgvibdx7MWW+eSbG+/16zjq5u/uXmx/n+3UuYtddELnrfLG585IUdEvz0KU3brbels4vr5y7l27cvZuUrW3jzAbvzuRMO5g37TmVrZzft67ewYt1mVqzdnNy/soWV67bQ2FDHnhPG8apJjewxcRyvSm+Tmxr8zcBsDNjVRH80cHFEvCt9fgFARPxjps7NaZ17JdUDLwItwPnZutl6/e0zb4ke4PEXX2FKcwN7TBi3U+vd9ugKPvezh1mzsYP6OvWZ4Mtt7ujiP+9/ju/duZhV67cyuamBNRs7dqhXXydaJjSytbObl3qZRatYX0fLbo0U6tQzxLSrO+jsjp7n3REU6kRDXR2Fgqivq6OhoGRZoQ4JOruCzq5uOrqT+86uZBud3d1EQH0hWb++IOoLdTTUiUK6TIIAiPSe5JtS9i+39FEkKXms7Zfvilr9oKvNV11dU5qKXP+Jowe1bn+JvpJRN3sDSzPPlwFH9VUnIjolrQV2T5ffV7bu3n0EeQ5wDsA+++xTQVhjyyGvmjCo9f7k0D359Wfeyq/+8DynHNE6YIIvGddQ4Oy37MfpR87gmvufY8mqDew5YRx7Tmxkz4nj2CO9n9pUpK4u+Zfe0tlF+ytJi//FtWnLf91m2l/ZQpAMG62vU5KM6+p6ntelHwJJ8u6moyvo6t6WzLsiaKhLE3i6bn0h+RAo1CWJuTP90Chto7RuR1d3T0IXmUQOSMmybck/eVxqvJQ+HHYpY42+U1gVCQLtwguPsfrCx7jh+s1NJYm+t7+W8r+CvupUsm6yMOJy4HJIWvQVxFUz9p48nnPffuCg1m0q1vPxt+5fUd3G+gLTpzRV/GFiZmNDJcMrlwEzMs+nA0zxEl4AAAS/SURBVOW/7e+pk3bdTAJWV7iumZkNo0oS/VzgIEn7SSoCpwFzyurMAc5KH38IuD2S789zgNMkNUraDzgIeGBoQjczs0oM2HWT9rmfB9xMMrzyyohYKOkSYF5EzAGuAH4saTFJS/60dN2Fkq4HFgGdwLkDjbgxM7Oh5R9MmZnlgC9qZmZWw5zozcxyzonezCznnOjNzHJuVJ6MldQOPNtH8TRg1QiGszMc2+A4tsFxbIOT19j2jYgdJ7JmlCb6/kia19eZ5WpzbIPj2AbHsQ1OLcbmrhszs5xzojczy7mxmOgvr3YA/XBsg+PYBsexDU7NxTbm+ujNzGznjMUWvZmZ7QQnejOznBsziV7SiZIel7RY0vnVjqecpGck/VHSfElVvSKbpCslrZS0ILNsqqRbJT2Z3k8ZRbFdLOn59NjNl3RSlWKbIekOSY9KWijpr9PlVT12/cQ1Wo7bOEkPSHo4je/L6fL9JN2fHrefppc5Hy2xXSXp6cyxO2KkY0vjKEj6g6Qb0+fDc8wiYtTfSC6P/BSwP1AEHgZmVTuushifAaZVO440lrcBrwcWZJb9M3B++vh84J9GUWwXA/9nFBy3vYDXp48nAE8As6p97PqJa7QcNwG7pY8bgPuBNwHXA6elyy8DPjmKYrsK+NAoOHafBa4BbkyfD8sxGyst+iOBxRGxJCK2AtcBp1Q5plErIu4mmRcg6xTgR+njHwHvH9GgUn3ENipExAsR8VD6+BXgUZI5jqt67PqJa1SIxPr0aUN6C+AdwM/T5VX5m+sntqqTNB14D/DD9LkYpmM2VhJ9bxOUj5o/9FQAt0h6MJ3ofLTZMyJegCRxAHtUOZ5y50l6JO3aqUq3UpakmcDrSFqAo+bYlcUFo+S4pV0Q84GVwK0k38DXRERnWqVq/7PlsUVE6dh9LT1235TUWIXQvgV8AehOn+/OMB2zsZLoK55kvIqOiYjXA+8GzpX0tmoHNIZ8DzgAOAJ4AfhGNYORtBvwC+BvImJdNWPJ6iWuUXPcIqIrIo4gmRf6SODQ3qqNbFTpTstik/Qa4ALg1cAbganA341kTJLeC6yMiAezi3upOiTHbKwk+lE/yXhELE/vVwK/JPljH01WSNoLIL1fWeV4ekTEivSfsRv4AVU8dpIaSJLpf0bEf6WLq37seotrNB23kohYA9xJ0g8+WVJputKq/89mYjsx7Q6LiNgC/Acjf+yOAU6W9AxJV/Q7SFr4w3LMxkqir2SC8qqR1CxpQukxcAKwoP+1Rlx2AvezgBuqGMt2Skk09QGqdOzSPtIrgEcj4l8zRVU9dn3FNYqOW4ukyenj8cA7Sc4j3AF8KK1Wlb+5PmJ7LPPBLZJ+8BE9dhFxQURMj4iZJPns9og4g+E6ZtU+67wTZ6dPIhlt8BTwxWrHUxbb/iQjgR4GFlY7PuBakq/yHSTfhs4m6f+7DXgyvZ86imL7MfBH4BGSpLpXlWJ7C8lX5UeA+entpGofu37iGi3H7XDgD2kcC4AL0+X7Aw8Ai4GfAY2jKLbb02O3APgJ6cicKh2/49g26mZYjpkvgWBmlnNjpevGzMwGyYnezCznnOjNzHLOid7MLOec6M3Mcs6J3sws55zozcxy7v8DuFcYwxwdTu0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training process \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = [robust_loss_history[i] for i in np.arange(len(robust_loss_history)) if (i+1)%size_of_dataset==0]\n",
    "x = [i+1 for i in np.arange(len(y))]\n",
    "x = np.array(x)\n",
    "plt.plot(x, y)\n",
    "plt.title('Model trained on robust dataset')\n",
    "plt.show()\n",
    "\n",
    "y = [non_robust_loss_history[i] for i in np.arange(len(non_robust_loss_history)) if (i+1)%size_of_dataset==0]\n",
    "x = [i+1 for i in np.arange(len(y))]\n",
    "x = np.array(x)\n",
    "plt.plot(x, y)\n",
    "plt.title('Model trained on non-robust dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01\tSuccess Rate = 55 / 1000 = 0.055\n",
      "Epsilon: 0.01\tSuccess Rate = 57 / 1000 = 0.057\n",
      "\n",
      "Epsilon: 0.01\tSuccess Rate = 72 / 1000 = 0.072\n",
      "Epsilon: 0.01\tSuccess Rate = 76 / 1000 = 0.076\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "requested resize to 1000x1x28x28 (784000 elements in total), but the given tensor has a size of 1x784 (784 elements). autograd's resize can only change the shape of a given tensor, while preserving the number of elements. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3bf1193a0b8a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, epsilon, X, Y, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-34a5f818be26>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 10 1, but got 2-dimensional input of size [1, 784] instead",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3bf1193a0b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mrobust_attack_success_rate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#         print(end - start)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3bf1193a0b8a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, epsilon, X, Y, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtrain\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, *sizes)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"non-inplace resize is deprecated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, tensor, sizes)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                 \u001b[0;34m\"tensor, while preserving the number of elements. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;34m'x'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 'x'.join(map(str, tensor.size())), tensor.numel()))\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: requested resize to 1000x1x28x28 (784000 elements in total), but the given tensor has a size of 1x784 (784 elements). autograd's resize can only change the shape of a given tensor, while preserving the number of elements. "
     ]
    }
   ],
   "source": [
    "# Measure attack success rate \n",
    "# 1. Design (apply) adversarial attacks \n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    \n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + (epsilon * sign_data_grad)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image\n",
    "\n",
    "def test(model, epsilon, X, Y, verbose=False):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    success_count = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for idx, data in enumerate(X):\n",
    "        data = torch.from_numpy(np.expand_dims(data, axis=0).astype(np.float32))\n",
    "            \n",
    "        target = np.array([Y[idx]]).astype(np.int64)\n",
    "        target = torch.from_numpy(target)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        try: \n",
    "            output = model.forward(data)\n",
    "        except:\n",
    "            train  = data.resize(X.shape[0], 1, 28, 28)\n",
    "            outputs = model.forward(train).detach().numpy()\n",
    "        \n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model.forward(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "            success_count += 1\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_sucess_rate = success_count/float(Y.shape[0])\n",
    "    if verbose:\n",
    "        print(\"Epsilon: {}\\tSuccess Rate = {} / {} = {}\".format(epsilon, success_count, Y.shape[0], final_sucess_rate))\n",
    "    \n",
    "    return final_sucess_rate\n",
    "\n",
    "# epsilons = [0, .01, .02, .03, .05, .1, .15, .2]\n",
    "for (robust_model, non_robust_model) in zip(robust_models, non_robust_models):\n",
    "    epsilons = [.01]\n",
    "    robust_pretrained_model = robust_model.eval()\n",
    "    non_robust_pretrained_model = non_robust_model.eval()\n",
    "    use_cuda=False\n",
    "\n",
    "    robust_attack_success_rate, non_robust_attack_success_rate = [], []\n",
    "    # Run test for each epsilon (robust)\n",
    "    for eps in epsilons:\n",
    "        start = time.time()\n",
    "        robust_attack_success_rate.append(test(robust_model, eps, test_X, test_Y, verbose=True))\n",
    "        end = time.time()\n",
    "#         print(end - start)\n",
    "\n",
    "    # Run test for each epsilon (non robust)\n",
    "    for eps in epsilons:\n",
    "        start = time.time()\n",
    "        non_robust_attack_success_rate.append(test(non_robust_model, eps, test_X, test_Y, verbose=True))\n",
    "        end = time.time()\n",
    "#         print(end - start)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print('Robustness indication (robust dataset):', robust_r)\n",
    "print('Robustness indication (non robust dataset):', non_robust_r)\n",
    "\n",
    "great_indication_count = 0\n",
    "num_of_comparision = len(robust_attack_success_rate)\n",
    "if robust_r < non_robust_r:\n",
    "    for i in range(num_of_comparision):\n",
    "        if robust_attack_success_rate[i] >= non_robust_attack_success_rate[i]:\n",
    "            great_indication_count += 1\n",
    "elif robust_r > non_robust_r:\n",
    "    for i in range(num_of_comparision):\n",
    "        if robust_attack_success_rate[i] <= non_robust_attack_success_rate[i]:\n",
    "            great_indication_count += 1\n",
    "else:\n",
    "    print('Weird, it merely impossible for two robustness indication to the same!')\n",
    "\n",
    "print(great_indication_count, num_of_comparision, great_indication_count/num_of_comparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_trails = 500                \n",
    "cum_related_rate = 0\n",
    "\n",
    "time_record_for_adv_est_r = []\n",
    "time_record_for_real_r = []\n",
    "\n",
    "for trail_idx in range(num_of_trails):\n",
    "    print('Trail:', trail_idx+1)\n",
    "\n",
    "    size_of_dataset = 500\n",
    "    robust_X, robust_Y = create_robust_dataset(size_of_dataset)\n",
    "    non_robust_X, non_robust_Y = create_non_robust_dataset(size_of_dataset)\n",
    "\n",
    "    start = time.time()\n",
    "    robust_r = compute_robustness_indication(robust_X, robust_Y)\n",
    "    end = time.time()\n",
    "    time_escape = end - start \n",
    "    time_record_for_adv_est_r.append(time_escape)\n",
    "        \n",
    "    non_robust_r = compute_robustness_indication(non_robust_X, non_robust_Y)\n",
    "\n",
    "    robust_loss_history, robust_model = generate_NaiveC(robust_X, robust_Y)\n",
    "    non_robust_loss_history, non_robust_model = generate_NaiveC(non_robust_X, non_robust_Y)\n",
    "\n",
    "    \n",
    "#     epsilons = [.02, .03, 0.5, 0.8, .1]\n",
    "    epsilons = [.1]\n",
    "    \n",
    "    \n",
    "    robust_pretrained_model = robust_model.eval()\n",
    "    non_robust_pretrained_model = non_robust_model.eval()\n",
    "    use_cuda=False\n",
    "\n",
    "    robust_attack_success_rate, non_robust_attack_success_rate = [], []\n",
    "    # Run test for each epsilon (robust)\n",
    "    for eps in epsilons:\n",
    "        start = time.time()\n",
    "        robust_attack_success_rate.append(test(robust_model, eps, test_X, test_Y))\n",
    "        end = time.time()\n",
    "        time_escape = end - start \n",
    "        time_record_for_real_r.append(time_escape)\n",
    "        \n",
    "    # Run test for each epsilon (non robust)\n",
    "    for eps in epsilons:\n",
    "        non_robust_attack_success_rate.append(test(non_robust_model, eps, test_X, test_Y))\n",
    "\n",
    "    great_indication_count = 0\n",
    "    num_of_comparision = len(robust_attack_success_rate)\n",
    "    if robust_r < non_robust_r:\n",
    "        for i in range(num_of_comparision):\n",
    "            if robust_attack_success_rate[i] >= non_robust_attack_success_rate[i]:\n",
    "                great_indication_count += 1\n",
    "    elif robust_r > non_robust_r:\n",
    "        for i in range(num_of_comparision):\n",
    "            if robust_attack_success_rate[i] <= non_robust_attack_success_rate[i]:\n",
    "                great_indication_count += 1\n",
    "    else:\n",
    "        print('Weird, it merely impossible for two robustness indication to the same!')\n",
    "\n",
    "    print(great_indication_count, num_of_comparision, great_indication_count/num_of_comparision)\n",
    "    cum_related_rate += great_indication_count/num_of_comparision\n",
    "    \n",
    "print(cum_related_rate/num_of_trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.array(time_record_for_adv_est_r)))\n",
    "print(np.mean(np.array(time_record_for_real_r)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
