{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n",
      "(1000, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuotzuyang/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'MNIST_models.CNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/kuotzuyang/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/kuotzuyang/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import PI\n",
    "\n",
    "meta_params = {\n",
    "    'num_of_train_dataset': 1000,\n",
    "    'num_of_test_dataset': 1000,\n",
    "    'is_flatten': False\n",
    "}\n",
    "\n",
    "PI = PI.PIInterface(meta_params)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from MNIST_models import *\n",
    "\n",
    "model = load_model('store/MNIST_CNN.pt')\n",
    "PI.set_model(model)\n",
    "# print('train acc:', PI.eval_model('train'))\n",
    "# print('test acc:', PI.eval_model('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "prefixs = ['store_zero/', 'store_one/', 'store_two/', 'store_three/', 'store_four/', \n",
    "           'store_five/', 'store_six/', 'store_seven/', 'store_eight/', 'store_nine/']     \n",
    "\n",
    "# LOAD \n",
    "guards = []\n",
    "for idx, prefix in enumerate(prefixs):\n",
    "    # LOAD TRAINED SUB-GUARD\n",
    "    guard_model = torch.load('store_subs/'+prefix+'guard.pt')\n",
    "    guards.append(guard_model)\n",
    "        \n",
    "# for idx, prefix in enumerate(prefixs):\n",
    "#     print('store_subs/'+prefix)\n",
    "#     fn = 'store_subs/'+prefix+'guard.pt'\n",
    "#     print(fn)\n",
    "    \n",
    "#     # LOAD DATASET \n",
    "#     adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "#     set_of_train_dataset, set_of_test_dataset = [], []\n",
    "#     for adv_type in adv_types:\n",
    "#         # extract from the store file \n",
    "#         if adv_type == 'None': fn_name = 'store_subs/'+prefix+'normal.txt'\n",
    "#         else: fn_name = 'store_subs/'+prefix+adv_type+'.txt'\n",
    "#         fp = open(fn_name, 'rb')\n",
    "#         set_of_signatures = pickle.load(fp)\n",
    "\n",
    "#         # separate and store in for later training and evaluation \n",
    "#         if adv_type == 'None': split_percentage = 0.8\n",
    "#         else: split_percentage = 0.8\n",
    "#         split_line = int(len(set_of_signatures)*split_percentage)\n",
    "#         train_set_of_signatures, test_set_of_signatures = set_of_signatures[:split_line], set_of_signatures[split_line:]\n",
    "#         set_of_train_dataset.append(train_set_of_signatures)\n",
    "#         set_of_test_dataset.append(test_set_of_signatures)\n",
    "#         fp.close()\n",
    "#         print(adv_type, len(set_of_signatures), len(train_set_of_signatures), len(test_set_of_signatures))\n",
    "#     print()\n",
    "    \n",
    "#     #####################################################################\n",
    "#     # TRAIN\n",
    "#     #####################################################################\n",
    "#     guard_model = Guard()\n",
    "#     guard_model.train()\n",
    "#     epoches = 8\n",
    "\n",
    "#     train_accs, test_accs, losses, set_train_sub_accs, set_test_sub_accs = train_guard_model(guard_model, set_of_train_dataset, set_of_test_dataset, adv_types, epoches)\n",
    "#     losses = [x.item() for x in losses]\n",
    "#     guard_model.eval()\n",
    "#     torch.save(guard_model, fn)\n",
    "    \n",
    "#     figsize = (12, 4)\n",
    "#     fig=plt.figure(figsize=figsize)\n",
    "\n",
    "#     num_of_epoches = len(set_train_sub_accs)\n",
    "#     num_of_adv_types = len(set_train_sub_accs[0])\n",
    "#     fig.add_subplot(1, 2, 1)\n",
    "#     for i in range(num_of_adv_types):\n",
    "#         adv_type_accs = [sub_accs[i] for sub_accs in set_train_sub_accs]\n",
    "#         smooth_adv_type_accs = gaussian_filter1d(adv_type_accs, sigma=1)\n",
    "#         plt.plot(smooth_adv_type_accs)\n",
    "\n",
    "#     # plt.legend(filtered_adv_types, loc='lower right')\n",
    "#     plt.legend(adv_types, loc='lower right')\n",
    "#     plt.title('train')\n",
    "#     plt.ylim([0, 1.05])\n",
    "\n",
    "#     num_of_epoches = len(set_test_sub_accs)\n",
    "#     num_of_adv_types = len(set_test_sub_accs[0])\n",
    "#     fig.add_subplot(1, 2, 2)\n",
    "#     for i in range(num_of_adv_types):\n",
    "#         adv_type_accs = [sub_accs[i] for sub_accs in set_test_sub_accs]\n",
    "#         smooth_adv_type_accs = gaussian_filter1d(adv_type_accs, sigma=1)\n",
    "#         plt.plot(smooth_adv_type_accs)\n",
    "\n",
    "#     plt.legend(adv_types, loc='lower right')\n",
    "#     plt.title('test')\n",
    "#     plt.ylim([0, 1.05])\n",
    "\n",
    "#     # plt.savefig('outputs.jpg')\n",
    "#     plt.show()\n",
    "#     #####################################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "correct_count: 883 total_count: 974\n",
      "acc: 0.9065708418891171\n",
      "\n",
      "FGSM\n",
      "correct_count: 735 total_count: 816\n",
      "acc: 0.9007352941176471\n",
      "\n",
      "JSMA\n",
      "correct_count: 916 total_count: 973\n",
      "acc: 0.9414182939362795\n",
      "\n",
      "CWL2\n",
      "correct_count: 782 total_count: 860\n",
      "acc: 0.9093023255813953\n",
      "\n",
      "LINFPGD\n",
      "correct_count: 532 total_count: 973\n",
      "acc: 0.5467625899280576\n",
      "\n",
      "LINFBI\n",
      "correct_count: 399 total_count: 957\n",
      "acc: 0.4169278996865204\n",
      "\n",
      "ENL1\n",
      "correct_count: 893 total_count: 1000\n",
      "acc: 0.893\n",
      "\n",
      "ST\n",
      "correct_count: 924 total_count: 988\n",
      "acc: 0.9352226720647774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "for adv_type in adv_types:\n",
    "    print(adv_type)\n",
    "    if adv_type == 'None': \n",
    "        PI.eval_sub_guards(guards)\n",
    "    else:\n",
    "        PI.eval_sub_guards(guards, adv_type)\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "correct_count: 642 total_count: 974\n",
      "acc: 0.6591375770020534\n",
      "\n",
      "FGSM\n",
      "correct_count: 815 total_count: 816\n",
      "acc: 0.9987745098039216\n",
      "\n",
      "JSMA\n",
      "correct_count: 965 total_count: 973\n",
      "acc: 0.9917780061664954\n",
      "\n",
      "CWL2\n",
      "correct_count: 815 total_count: 860\n",
      "acc: 0.9476744186046512\n",
      "\n",
      "LINFPGD\n",
      "correct_count: 935 total_count: 973\n",
      "acc: 0.9609455292908531\n",
      "\n",
      "LINFBI\n",
      "correct_count: 896 total_count: 957\n",
      "acc: 0.9362591431556949\n",
      "\n",
      "ENL1\n",
      "correct_count: 956 total_count: 1000\n",
      "acc: 0.956\n",
      "\n",
      "ST\n",
      "correct_count: 960 total_count: 988\n",
      "acc: 0.97165991902834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guard_model = torch.load('store/guard.pt')\n",
    "adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "for adv_type in adv_types:\n",
    "    print(adv_type)\n",
    "    if adv_type == 'None': \n",
    "        PI.eval_guard(guard_model)\n",
    "    else:\n",
    "        PI.eval_guard(guard_model, adv_type)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
