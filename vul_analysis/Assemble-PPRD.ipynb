{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 100\n",
      "(100, 1, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuotzuyang/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'MNIST_models.CNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/kuotzuyang/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/kuotzuyang/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import PI\n",
    "\n",
    "meta_params = {\n",
    "    'num_of_train_dataset': 1000,\n",
    "    'num_of_test_dataset': 100,\n",
    "    'is_flatten': False\n",
    "}\n",
    "\n",
    "PI = PI.PIInterface(meta_params)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from MNIST_models import *\n",
    "\n",
    "model = load_model('store/MNIST_CNN.pt')\n",
    "PI.set_model(model)\n",
    "# print('train acc:', PI.eval_model('train'))\n",
    "# print('test acc:', PI.eval_model('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1000 800 200\n",
      "FGSM 813 650 163\n",
      "JSMA 966 772 194\n",
      "CWL2 877 701 176\n",
      "LINFPGD 978 782 196\n",
      "LINFBI 970 776 194\n",
      "ENL1 1000 800 200\n",
      "ST 991 792 199\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "prefixs = ['store_zero/', 'store_one/', 'store_two/', 'store_three/', 'store_four/', \n",
    "           'store_five/', 'store_six/', 'store_seven/', 'store_eight/', 'store_nine/']     \n",
    "\n",
    "# LOAD \n",
    "# guards = []\n",
    "# for idx, prefix in enumerate(prefixs):\n",
    "#     # LOAD TRAINED SUB-GUARD\n",
    "#     guard_model = torch.load('store_subs/'+prefix+'guard.pt')\n",
    "#     guards.append(guard_model)\n",
    "\n",
    "guards = []\n",
    "for _ in range(10):\n",
    "    gaurd_model = Guard()\n",
    "    guards.append(gaurd_model)\n",
    "    \n",
    "    \n",
    "prefix = 'store/'    \n",
    "# LOAD \n",
    "adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "set_of_train_dataset, set_of_test_dataset = [], []\n",
    "\n",
    "for adv_type in adv_types:\n",
    "    # extract from the store file \n",
    "    if adv_type == 'None': fn_name=prefix+'normal.txt'\n",
    "    else: fn_name=prefix+adv_type+'.txt'\n",
    "    fp = open(fn_name, 'rb')\n",
    "    set_of_signatures = pickle.load(fp)\n",
    "    \n",
    "    # separate and store in for later training and evaluation \n",
    "    if adv_type == 'None': split_percentage = 0.8\n",
    "    else: split_percentage = 0.8\n",
    "    split_line = int(len(set_of_signatures)*split_percentage)\n",
    "    train_set_of_signatures, test_set_of_signatures = set_of_signatures[:split_line], set_of_signatures[split_line:]\n",
    "    set_of_train_dataset.append(train_set_of_signatures)\n",
    "    set_of_test_dataset.append(test_set_of_signatures)\n",
    "    fp.close()\n",
    "    print(adv_type, len(set_of_signatures), len(train_set_of_signatures), len(test_set_of_signatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign correct: 628 / 800\n",
      "adv ( FGSM ) correct: 650 / 650\n",
      "adv ( JSMA ) correct: 767 / 772\n",
      "adv ( CWL2 ) correct: 660 / 701\n",
      "adv ( LINFPGD ) correct: 773 / 782\n",
      "adv ( LINFBI ) correct: 751 / 776\n",
      "adv ( ENL1 ) correct: 762 / 800\n",
      "adv ( ST ) correct: 777 / 792\n",
      "acc: 0.949777704594105\n",
      "\n",
      "benign correct: 153 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 191 / 194\n",
      "adv ( CWL2 ) correct: 156 / 176\n",
      "adv ( LINFPGD ) correct: 194 / 196\n",
      "adv ( LINFBI ) correct: 191 / 194\n",
      "adv ( ENL1 ) correct: 182 / 200\n",
      "adv ( ST ) correct: 194 / 199\n",
      "acc: 0.9356110381077529\n",
      "\n",
      "epoch: 1 loss: 2332.85302734375\n",
      "acc (train): 0.949777704594105\n",
      "acc (test): 0.9356110381077529\n",
      "\n",
      "one epoch training time in seconds 697.067898\n",
      "benign correct: 699 / 800\n",
      "adv ( FGSM ) correct: 650 / 650\n",
      "adv ( JSMA ) correct: 771 / 772\n",
      "adv ( CWL2 ) correct: 665 / 701\n",
      "adv ( LINFPGD ) correct: 781 / 782\n",
      "adv ( LINFBI ) correct: 770 / 776\n",
      "adv ( ENL1 ) correct: 777 / 800\n",
      "adv ( ST ) correct: 783 / 792\n",
      "acc: 0.9708546023382183\n",
      "\n",
      "benign correct: 162 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 192 / 194\n",
      "adv ( CWL2 ) correct: 164 / 176\n",
      "adv ( LINFPGD ) correct: 192 / 196\n",
      "adv ( LINFBI ) correct: 191 / 194\n",
      "adv ( ENL1 ) correct: 192 / 200\n",
      "adv ( ST ) correct: 196 / 199\n",
      "acc: 0.9540078843626807\n",
      "\n",
      "epoch: 2 loss: 1124.524658203125\n",
      "acc (train): 0.9708546023382183\n",
      "acc (test): 0.9540078843626807\n",
      "\n",
      "one epoch training time in seconds 818.675167\n",
      "benign correct: 707 / 800\n",
      "adv ( FGSM ) correct: 648 / 650\n",
      "adv ( JSMA ) correct: 771 / 772\n",
      "adv ( CWL2 ) correct: 668 / 701\n",
      "adv ( LINFPGD ) correct: 777 / 782\n",
      "adv ( LINFBI ) correct: 768 / 776\n",
      "adv ( ENL1 ) correct: 773 / 800\n",
      "adv ( ST ) correct: 776 / 792\n",
      "acc: 0.9695372962292113\n",
      "\n",
      "benign correct: 172 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 193 / 194\n",
      "adv ( CWL2 ) correct: 164 / 176\n",
      "adv ( LINFPGD ) correct: 196 / 196\n",
      "adv ( LINFBI ) correct: 192 / 194\n",
      "adv ( ENL1 ) correct: 191 / 200\n",
      "adv ( ST ) correct: 192 / 199\n",
      "acc: 0.9612352168199737\n",
      "\n",
      "epoch: 3 loss: 882.7689819335938\n",
      "acc (train): 0.9695372962292113\n",
      "acc (test): 0.9612352168199737\n",
      "\n",
      "one epoch training time in seconds 1186.22622\n",
      "benign correct: 695 / 800\n",
      "adv ( FGSM ) correct: 648 / 650\n",
      "adv ( JSMA ) correct: 770 / 772\n",
      "adv ( CWL2 ) correct: 681 / 701\n",
      "adv ( LINFPGD ) correct: 781 / 782\n",
      "adv ( LINFBI ) correct: 771 / 776\n",
      "adv ( ENL1 ) correct: 793 / 800\n",
      "adv ( ST ) correct: 790 / 792\n",
      "acc: 0.9762884900378725\n",
      "\n",
      "benign correct: 155 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 194 / 194\n",
      "adv ( CWL2 ) correct: 165 / 176\n",
      "adv ( LINFPGD ) correct: 195 / 196\n",
      "adv ( LINFBI ) correct: 194 / 194\n",
      "adv ( ENL1 ) correct: 196 / 200\n",
      "adv ( ST ) correct: 196 / 199\n",
      "acc: 0.9579500657030223\n",
      "\n",
      "epoch: 4 loss: 728.2136840820312\n",
      "acc (train): 0.9762884900378725\n",
      "acc (test): 0.9579500657030223\n",
      "\n",
      "one epoch training time in seconds 1121.4514289999997\n",
      "benign correct: 645 / 800\n",
      "adv ( FGSM ) correct: 649 / 650\n",
      "adv ( JSMA ) correct: 772 / 772\n",
      "adv ( CWL2 ) correct: 693 / 701\n",
      "adv ( LINFPGD ) correct: 781 / 782\n",
      "adv ( LINFBI ) correct: 773 / 776\n",
      "adv ( ENL1 ) correct: 796 / 800\n",
      "adv ( ST ) correct: 787 / 792\n",
      "acc: 0.9708546023382183\n",
      "\n",
      "benign correct: 149 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 194 / 194\n",
      "adv ( CWL2 ) correct: 166 / 176\n",
      "adv ( LINFPGD ) correct: 195 / 196\n",
      "adv ( LINFBI ) correct: 194 / 194\n",
      "adv ( ENL1 ) correct: 196 / 200\n",
      "adv ( ST ) correct: 198 / 199\n",
      "acc: 0.9559789750328516\n",
      "\n",
      "epoch: 5 loss: 620.466552734375\n",
      "acc (train): 0.9708546023382183\n",
      "acc (test): 0.9559789750328516\n",
      "\n",
      "one epoch training time in seconds 801.6309499999998\n",
      "benign correct: 765 / 800\n",
      "adv ( FGSM ) correct: 648 / 650\n",
      "adv ( JSMA ) correct: 768 / 772\n",
      "adv ( CWL2 ) correct: 662 / 701\n",
      "adv ( LINFPGD ) correct: 770 / 782\n",
      "adv ( LINFBI ) correct: 763 / 776\n",
      "adv ( ENL1 ) correct: 777 / 800\n",
      "adv ( ST ) correct: 778 / 792\n",
      "acc: 0.9766178165651244\n",
      "\n",
      "benign correct: 184 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 194 / 194\n",
      "adv ( CWL2 ) correct: 158 / 176\n",
      "adv ( LINFPGD ) correct: 193 / 196\n",
      "adv ( LINFBI ) correct: 193 / 194\n",
      "adv ( ENL1 ) correct: 190 / 200\n",
      "adv ( ST ) correct: 193 / 199\n",
      "acc: 0.9645203679369251\n",
      "\n",
      "epoch: 6 loss: 567.6691284179688\n",
      "acc (train): 0.9766178165651244\n",
      "acc (test): 0.9645203679369251\n",
      "\n",
      "one epoch training time in seconds 898.7607900000003\n",
      "benign correct: 746 / 800\n",
      "adv ( FGSM ) correct: 650 / 650\n",
      "adv ( JSMA ) correct: 772 / 772\n",
      "adv ( CWL2 ) correct: 672 / 701\n",
      "adv ( LINFPGD ) correct: 768 / 782\n",
      "adv ( LINFBI ) correct: 769 / 776\n",
      "adv ( ENL1 ) correct: 788 / 800\n",
      "adv ( ST ) correct: 784 / 792\n",
      "acc: 0.9795817553103903\n",
      "\n",
      "benign correct: 176 / 200\n",
      "adv ( FGSM ) correct: 163 / 163\n",
      "adv ( JSMA ) correct: 194 / 194\n",
      "adv ( CWL2 ) correct: 160 / 176\n",
      "adv ( LINFPGD ) correct: 192 / 196\n",
      "adv ( LINFBI ) correct: 190 / 194\n",
      "adv ( ENL1 ) correct: 191 / 200\n",
      "adv ( ST ) correct: 198 / 199\n",
      "acc: 0.961892247043364\n",
      "\n",
      "epoch: 7 loss: 664.9112548828125\n",
      "acc (train): 0.9795817553103903\n",
      "acc (test): 0.961892247043364\n",
      "\n",
      "one epoch training time in seconds 812.866387\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "guard_model = AssemebleGuard(guards)\n",
    "guard_model.train()\n",
    "epoches = 10\n",
    "\n",
    "train_accs, test_accs, losses, set_train_sub_accs, set_test_sub_accs = train_guard_model(guard_model, set_of_train_dataset, set_of_test_dataset, adv_types, epoches)\n",
    "losses = [x.item() for x in losses]\n",
    "guard_model.eval()\n",
    "# torch.save(guard_model, 'store/guard.pt')\n",
    "# guard_model = torch.load('store/guard.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "smooth_train_accs = gaussian_filter1d(train_accs, sigma=1)\n",
    "smooth_test_accs = gaussian_filter1d(test_accs, sigma=1)\n",
    "smooth_losses = gaussian_filter1d(losses, sigma=1)\n",
    "norm_smooth_losses = [float(i)/max(smooth_losses) for i in smooth_losses]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(smooth_train_accs)\n",
    "plt.plot(smooth_test_accs)\n",
    "plt.plot(norm_smooth_losses)\n",
    "plt.title('model accuracy and loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train acc', 'test acc', 'loss'], loc='lower right')\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "# plt.savefig('outputs.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_guard_model(guard_model, set_of_test_dataset, adv_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (12, 4)\n",
    "fig=plt.figure(figsize=figsize)\n",
    "\n",
    "num_of_epoches = len(set_train_sub_accs)\n",
    "num_of_adv_types = len(set_train_sub_accs[0])\n",
    "fig.add_subplot(1, 2, 1)\n",
    "for i in range(num_of_adv_types):\n",
    "    adv_type_accs = [sub_accs[i] for sub_accs in set_train_sub_accs]\n",
    "    smooth_adv_type_accs = gaussian_filter1d(adv_type_accs, sigma=1)\n",
    "    plt.plot(smooth_adv_type_accs)\n",
    "    \n",
    "# plt.legend(filtered_adv_types, loc='lower right')\n",
    "plt.legend(adv_types, loc='lower right')\n",
    "plt.title('train')\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "num_of_epoches = len(set_test_sub_accs)\n",
    "num_of_adv_types = len(set_test_sub_accs[0])\n",
    "fig.add_subplot(1, 2, 2)\n",
    "for i in range(num_of_adv_types):\n",
    "    adv_type_accs = [sub_accs[i] for sub_accs in set_test_sub_accs]\n",
    "    smooth_adv_type_accs = gaussian_filter1d(adv_type_accs, sigma=1)\n",
    "    plt.plot(smooth_adv_type_accs)\n",
    "    \n",
    "plt.legend(adv_types, loc='lower right')\n",
    "plt.title('test')\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "plt.savefig('assemble_10_untrained_one_PPRD.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare assemble_10_untrained_one_PPRD and assemble_10_trained_one_PPRD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
