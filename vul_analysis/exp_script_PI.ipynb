{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our objective: robustify a given neural network \n",
    "0. Prepare for experiments (DONE)\n",
    "1. Display the pattern how benign samples and adversarial samples being evalauted by PI (e.g., B->B->B->B, B->B->B->A). (DONE)\n",
    "2. Identify the layer required further improvement (PENDING)\n",
    "3. A. Robustify model (PENDING)\n",
    "3. B. Store the robustified model (PENDING)\n",
    "4. Evalaute effectiveness (whether robustified model truly enhance the robustness in terms of attack success rate Or PI indentification rate) (PENDING)\n",
    "\n",
    "##### Sub tasks (compulsory functionalities to achieve above procedures \n",
    "1. Print out the distribution after robustifying (DONE)\n",
    "2. Complete robustified CNN (DONE)\n",
    "\n",
    "##### Questions \n",
    "1. What if we re-train existing model by inserting a dropout layer instead of train a completely new robustified model? (PENDING)\n",
    "2. A. Experimental results? dropout rate of certain layer v.s. distribution(PENDING)\n",
    "2. B. Experimental results? dropout rate of certain layer v.s. attack success rate(PENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_LPs           : 4\n",
      "size_of_train_set    : 1000\n",
      "size_of_test_set     : 50\n",
      "flatten              : False\n",
      "model_type           : CNN\n",
      "adv_attack           : i_FGSM\n",
      "Train dataset\n",
      "(1000, 1, 28, 28) (1000,)\n",
      "Test dataset\n",
      "(50, 1, 28, 28) (50,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "0. Prepare for experiments \n",
    "'''\n",
    "%matplotlib inline\n",
    "import property_inference_interface\n",
    "PI = property_inference_interface.PropertyInferenceInterface()\n",
    "\n",
    "meta_params = {\n",
    "    'num_of_LPs': 4,\n",
    "    'size_of_train_set': 1000,\n",
    "    'size_of_test_set': 50,\n",
    "    'flatten': False, \n",
    "    'model_type': 'CNN',\n",
    "    'adv_attack': 'i_FGSM'\n",
    "}\n",
    "\n",
    "PI.set_meta_params(meta_params)\n",
    "PI.print_meta_params()\n",
    "PI.prepare_dataset()\n",
    "PI.print_dataset_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate accurancy: original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ( train ) accurancy: 0.991\n",
      "Model ( test ) accurancy: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0. Prepare for experiments \n",
    "'''\n",
    "# PI.generate_model(num_of_epochs=15)\n",
    "# PI.store_model('MNIST_CNN.pt')\n",
    "PI.load_model('MNIST_CNN.pt')\n",
    "\n",
    "print('Evaluate accurancy: original')\n",
    "PI.eval_model('train', on_robustified_model=False)\n",
    "PI.eval_model('test', on_robustified_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "0. Prepare for experiments \n",
    "'''\n",
    "PI.generate_LPs()\n",
    "(B_detect_ratio, A_detect_ratio), (B_LPs, A_LPs), (B_LPs_score, A_LPs_score) = PI.evaluate_algorithm_on_test_set(verbose=True)\n",
    "\n",
    "# B: Benign (normal) samples within test dataset \n",
    "# B2: Benign (normal) samples within train dataset \n",
    "# A: Adversarial samples based on benign samples within test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Display the pattern how benign samples and adversarial samples being evalauted by PI (e.g., B->B->B->B, B->B->B->A).\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(B_detect_ratio, A_detect_ratio)\n",
    "\n",
    "qr = '95'\n",
    "BLPs, ALPs = np.array(B_LPs), np.array(A_LPs) \n",
    "print(BLPs.shape, ALPs.shape)\n",
    "\n",
    "BLPs[BLPs=='benign'] = 1\n",
    "BLPs[BLPs=='adversarial'] = 0\n",
    "BLPs = BLPs.astype(np.int)\n",
    "prob_BLPs = np.sum(BLPs, axis=0) / BLPs.shape[0]\n",
    "\n",
    "ALPs[ALPs=='benign'] = 1\n",
    "ALPs[ALPs=='adversarial'] = 0\n",
    "ALPs = ALPs.astype(np.int)\n",
    "prob_ALPs = np.sum(ALPs, axis=0) / ALPs.shape[0]\n",
    "\n",
    "print('This indicates the portion of inputs to be judged as \"benign\"')\n",
    "print(prob_BLPs, 'test dataset (benign)')\n",
    "print(prob_ALPs, 'test dataset (adversarial)')\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "num_of_layers = 4\n",
    "index = np.arange(num_of_layers)\n",
    "bar_width, opacity = 0.2, 0.7\n",
    "\n",
    "rects1 = plt.bar(index, prob_BLPs, bar_width, alpha=opacity, color='g', label='Test Ben')\n",
    "rects2 = plt.bar(index + bar_width, prob_ALPs, bar_width, alpha=opacity, color='r', label='Test Ben')\n",
    "\n",
    "plt.xlabel('I-th layer')\n",
    "plt.ylabel('Benign ratio')\n",
    "plt.title('Benign ratio in different layers ('+qr+'qr)')\n",
    "plt.xticks(index + bar_width, ('1', '2', '3', '4'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "B_LPs_score, A_LPs_score = np.array(B_LPs_score), np.array(A_LPs_score)\n",
    "for i in range(B_LPs_score.shape[1]):\n",
    "    B_score, A_score = B_LPs_score[:,i], A_LPs_score[:, i]\n",
    "    B_indices, A_indices = np.arange(B_score.shape[0]), np.arange(A_score.shape[0])\n",
    "    plt.plot(B_score, B_indices, 'go')\n",
    "    plt.plot(A_score, A_indices, 'ro')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Identify the layer required further improvement (PENDING)\n",
    "'''\n",
    "# func (for automatically locate which layer should be further improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Robustify model \n",
    "let's say it's the 3rd layer \n",
    "'''\n",
    "\n",
    "PI.generate_robustified_model('CNN', 15, 0.3)\n",
    "print('Evaluate accurancy: original')\n",
    "PI.eval_model('train', on_robustified_model=False)\n",
    "PI.eval_model('test', on_robustified_model=False)\n",
    "print('Evaluate accurancy: robustified')\n",
    "PI.eval_model('train', on_robustified_model=True)\n",
    "PI.eval_model('test', on_robustified_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustify_by_dr(PI):\n",
    "    import copy\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    PI.model = copy.deepcopy(PI.robustified_model)\n",
    "    PI.generate_LPs()\n",
    "    (B_detect_ratio, A_detect_ratio), (B_LPs, A_LPs), (B_LPs_score, A_LPs_score) = PI.evaluate_algorithm_on_test_set(verbose=False)\n",
    "    print(B_detect_ratio, A_detect_ratio)\n",
    "\n",
    "    qr = '95'\n",
    "    BLPs, ALPs = np.array(B_LPs), np.array(A_LPs) \n",
    "    print(BLPs.shape, ALPs.shape)\n",
    "\n",
    "    BLPs[BLPs=='benign'] = 1\n",
    "    BLPs[BLPs=='adversarial'] = 0\n",
    "    BLPs = BLPs.astype(np.int)\n",
    "    prob_BLPs = np.sum(BLPs, axis=0) / BLPs.shape[0]\n",
    "\n",
    "    ALPs[ALPs=='benign'] = 1\n",
    "    ALPs[ALPs=='adversarial'] = 0\n",
    "    ALPs = ALPs.astype(np.int)\n",
    "    prob_ALPs = np.sum(ALPs, axis=0) / ALPs.shape[0]\n",
    "\n",
    "    print('This indicates the portion of inputs to be judged as \"benign\"')\n",
    "    print(prob_BLPs, 'test dataset (benign)')\n",
    "    print(prob_ALPs, 'test dataset (adversarial)')\n",
    "    return (prob_ALPs, prob_BLPs, A_LPs_score, B_LPs_score)\n",
    "\n",
    "def draw(results):\n",
    "    prob_ALPs, prob_BLPs, A_LPs_score, B_LPs_score = results\n",
    "    \n",
    "    # create plot\n",
    "    num_of_layers = 4\n",
    "    index = np.arange(num_of_layers)\n",
    "    bar_width, opacity = 0.2, 0.7\n",
    "\n",
    "    rects1 = plt.bar(index, prob_BLPs, bar_width, alpha=opacity, color='g', label='Test Ben')\n",
    "    rects2 = plt.bar(index + bar_width, prob_ALPs, bar_width, alpha=opacity, color='r', label='Test Ben')\n",
    "\n",
    "    plt.xlabel('I-th layer')\n",
    "    plt.ylabel('Benign ratio')\n",
    "    plt.title('Benign ratio in different layers ('+qr+'qr)')\n",
    "    plt.xticks(index + bar_width, ('1', '2', '3', '4'))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(18,3))\n",
    "    B_LPs_score, A_LPs_score = np.array(B_LPs_score), np.array(A_LPs_score)\n",
    "    for i in range(B_LPs_score.shape[1]):\n",
    "        B_score, A_score = B_LPs_score[:,i], A_LPs_score[:, i]\n",
    "        B_indices, A_indices = np.arange(B_score.shape[0]), np.arange(A_score.shape[0])\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.plot(B_score, B_indices, 'go')\n",
    "        plt.plot(A_score, A_indices, 'ro')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = robustify_by_dr(PI)\n",
    "draw(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
