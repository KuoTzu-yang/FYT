{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The singature should be of float type ... DONE <br/>\n",
    "Integrate FGSM ... DONE  <br/>\n",
    "Visualize three adv samples (at the beginning of this notebook) ... DONE  <br/>\n",
    "Integrate more attacks ... DONE  <br/>\n",
    "Simply the code (create individually -> in a simple list) ... DONE <br/>\n",
    "Try to enhance the ASRs ... DONE <br/>\n",
    "Generate and store all possible attacks you could generate ... <br/>\n",
    "Complete the generalization of the same type of adv attacks ...  <br/>\n",
    "(if fail) -> try DRAW architecture ...  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'MNIST_models.CNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.98\n",
      "test acc: 0.99\n"
     ]
    }
   ],
   "source": [
    "import PI\n",
    "\n",
    "meta_params = {\n",
    "    'num_of_train_dataset': 1000,\n",
    "    'num_of_test_dataset': 100,\n",
    "    'is_flatten': False\n",
    "}\n",
    "\n",
    "PI = PI.PIInterface(meta_params)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from MNIST_models import *\n",
    "# model = CNN()\n",
    "# loss_func, optimizer = nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# model = PI.train_model(model, loss_func, optimizer, 3)\n",
    "# PI.set_model(model)\n",
    "# print('train acc:', PI.eval_model('train'))\n",
    "# print('test acc:', PI.eval_model('test'))\n",
    "# print()\n",
    "\n",
    "model = load_model('store/MNIST_CNN.pt')\n",
    "PI.set_model(model)\n",
    "print('train acc:', PI.eval_model('train'))\n",
    "print('test acc:', PI.eval_model('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize the benign input and corresponding adv samples \n",
    "# samples, labels = PI.train_dataset\n",
    "\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np\n",
    "# import attacker\n",
    "# import time\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# # adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'L1PGD', 'L2PGD', 'LINFPGD', 'L2BI', 'LINFBI', 'ENL1', 'DDNL2', 'LBFGS', 'SP', 'LS', 'ST']\n",
    "# adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "# print(len(adv_types))\n",
    "# formatted_adv_types = [adv_type.ljust(6) for adv_type in adv_types]\n",
    "# print('  '+' '.join(formatted_adv_types))\n",
    "\n",
    "# figsize=(5, 5)\n",
    "# fig=plt.figure(figsize=figsize)\n",
    "# columns, num_of_rows = len(adv_types), 8\n",
    "\n",
    "# for i in range(num_of_rows):\n",
    "#     sample, label = samples[i], labels[i]\n",
    "#     for col_index in range(columns):  \n",
    "#         adv_type = adv_types[col_index]\n",
    "#         if adv_type == 'None': \n",
    "#             plt_sample = sample \n",
    "#         else:\n",
    "#             plt_sample = PI.generate_adv_img(sample, label, model, adv_type)\n",
    "#             if plt_sample is None: \n",
    "#                 plt_sample = np.zeros((1, 28, 28)) \n",
    "            \n",
    "\n",
    "#         fig.add_subplot(num_of_rows, columns, (col_index+1)+(i*columns))\n",
    "#         plt.imshow(np.squeeze(plt_sample), cmap='gray')\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "\n",
    "# fig.savefig('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1000 800 200\n",
      "FGSM 813 650 163\n",
      "JSMA 966 772 194\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# STORE\n",
    "# adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "# adv_types = ['CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "# for adv_type in adv_types:\n",
    "#     if adv_type == 'None': \n",
    "#         fn_name='store/normal.txt'\n",
    "#         set_of_signatures = PI.generate_signatures() \n",
    "#     else: \n",
    "#         fn_name='store/'+adv_type+'.txt'\n",
    "#         set_of_signatures = PI.generate_signatures(adv_type=adv_type)\n",
    "    \n",
    "#     print(adv_type, len(set_of_signatures))\n",
    "#     with open(fn_name, \"wb\") as fp:   \n",
    "#         pickle.dump(set_of_signatures, fp)\n",
    "    \n",
    "    \n",
    "# LOAD \n",
    "# adv_types = ['None', 'FGSM', 'JSMA', 'CWL2', 'LINFPGD', 'LINFBI', 'ENL1', 'ST']\n",
    "adv_types = ['None', 'FGSM', 'JSMA']\n",
    "set_of_train_dataset, set_of_test_dataset = [], []\n",
    "split_percentage = 0.8\n",
    "\n",
    "for adv_type in adv_types:\n",
    "    # extract from the store file \n",
    "    if adv_type == 'None': fn_name='store/normal.txt'\n",
    "    else: fn_name='store/'+adv_type+'.txt'\n",
    "    fp = open(fn_name, 'rb')\n",
    "    set_of_signatures = pickle.load(fp)\n",
    "    \n",
    "    # separate and store in for later training and evaluation \n",
    "    split_line = int(len(set_of_signatures)*split_percentage)\n",
    "    train_set_of_signatures, test_set_of_signatures = set_of_signatures[:split_line], set_of_signatures[split_line:]\n",
    "    set_of_train_dataset.append(train_set_of_signatures)\n",
    "    set_of_test_dataset.append(test_set_of_signatures)\n",
    "    fp.close()\n",
    "    print(adv_type, len(set_of_signatures), len(train_set_of_signatures), len(test_set_of_signatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign correct: 798 / 800\n",
      "adv ( FGSM ) correct: 631 / 650\n",
      "adv ( JSMA ) correct: 772 / 772\n",
      "epoch: 1 loss: 99.35013580322266\n",
      "acc: 0.9905490549054905\n",
      "benign correct: 776 / 800\n",
      "adv ( FGSM ) correct: 624 / 650\n",
      "adv ( JSMA ) correct: 772 / 772\n",
      "epoch: 2 loss: 309.6373291015625\n",
      "acc: 0.9774977497749775\n",
      "benign correct: 785 / 800\n",
      "adv ( FGSM ) correct: 632 / 650\n",
      "adv ( JSMA ) correct: 771 / 772\n",
      "epoch: 3 loss: 113.44163513183594\n",
      "acc: 0.9846984698469847\n",
      "benign correct: 788 / 800\n",
      "adv ( FGSM ) correct: 639 / 650\n",
      "adv ( JSMA ) correct: 772 / 772\n",
      "epoch: 4 loss: 143.84078979492188\n",
      "acc: 0.9896489648964897\n",
      "benign correct: 774 / 800\n",
      "adv ( FGSM ) correct: 629 / 650\n",
      "adv ( JSMA ) correct: 766 / 772\n",
      "epoch: 5 loss: 202.35244750976562\n",
      "acc: 0.9761476147614762\n",
      "benign correct: 757 / 800\n",
      "adv ( FGSM ) correct: 639 / 650\n",
      "adv ( JSMA ) correct: 770 / 772\n",
      "epoch: 6 loss: 303.2123107910156\n",
      "acc: 0.9747974797479748\n",
      "benign correct: 772 / 800\n",
      "adv ( FGSM ) correct: 640 / 650\n",
      "adv ( JSMA ) correct: 767 / 772\n",
      "epoch: 7 loss: 171.71377563476562\n",
      "acc: 0.9806480648064807\n",
      "benign correct: 776 / 800\n",
      "adv ( FGSM ) correct: 639 / 650\n",
      "adv ( JSMA ) correct: 766 / 772\n",
      "epoch: 8 loss: 165.8268280029297\n",
      "acc: 0.9815481548154815\n",
      "benign correct: 775 / 800\n",
      "adv ( FGSM ) correct: 643 / 650\n",
      "adv ( JSMA ) correct: 766 / 772\n",
      "epoch: 9 loss: 164.22528076171875\n",
      "acc: 0.9828982898289829\n",
      "benign correct: 783 / 800\n",
      "adv ( FGSM ) correct: 644 / 650\n",
      "adv ( JSMA ) correct: 763 / 772\n",
      "epoch: 10 loss: 121.48213958740234\n",
      "acc: 0.9855985598559855\n",
      "benign correct: 784 / 800\n",
      "adv ( FGSM ) correct: 646 / 650\n",
      "adv ( JSMA ) correct: 767 / 772\n",
      "epoch: 11 loss: 89.18548583984375\n",
      "acc: 0.9887488748874887\n",
      "benign correct: 783 / 800\n",
      "adv ( FGSM ) correct: 644 / 650\n",
      "adv ( JSMA ) correct: 769 / 772\n",
      "epoch: 12 loss: 84.07026672363281\n",
      "acc: 0.9882988298829883\n",
      "benign correct: 785 / 800\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "guard_model = Guard()\n",
    "guard_model.train()\n",
    "epoches = 15\n",
    "\n",
    "accs, losses = train_guard_model(guard_model, set_of_train_dataset, adv_types, epoches)\n",
    "losses = [x.item() for x in losses]\n",
    "guard_model.eval()\n",
    "torch.save(guard_model, 'store/guard.pt')\n",
    "# guard_model = torch.load('guard.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "smooth_accs = gaussian_filter1d(accs, sigma=2)\n",
    "smooth_losses = gaussian_filter1d(losses, sigma=2)\n",
    "norm_smooth_losses = [float(i)/max(smooth_losses) for i in smooth_losses]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# declare a figure\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(smooth_accs)\n",
    "plt.plot(norm_smooth_losses)\n",
    "plt.title('model accuracy and loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc', 'loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_guard_model(guard_model, set_of_test_dataset, adv_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
